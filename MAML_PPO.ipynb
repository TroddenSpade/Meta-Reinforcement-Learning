{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0u8jyVEHU90_",
        "outputId": "3834b908-a0f6-4135-af0e-33a403bbab66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgl1-mesa-dev is already the newest version (20.0.8-0ubuntu1~18.04.1).\n",
            "libgl1-mesa-dev set to manually installed.\n",
            "software-properties-common is already the newest version (0.96.24.32.18).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  glew-utils\n",
            "The following NEW packages will be installed:\n",
            "  libgl1-mesa-glx libglew-dev libglew2.0 libosmesa6 libosmesa6-dev\n",
            "0 upgraded, 5 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 2,916 kB of archives.\n",
            "After this operation, 12.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgl1-mesa-glx amd64 20.0.8-0ubuntu1~18.04.1 [5,532 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglew2.0 amd64 2.0.0-5 [140 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libglew-dev amd64 2.0.0-5 [120 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libosmesa6 amd64 20.0.8-0ubuntu1~18.04.1 [2,641 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libosmesa6-dev amd64 20.0.8-0ubuntu1~18.04.1 [8,828 B]\n",
            "Fetched 2,916 kB in 1s (3,341 kB/s)\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libglew2.0:amd64.\n",
            "Preparing to unpack .../libglew2.0_2.0.0-5_amd64.deb ...\n",
            "Unpacking libglew2.0:amd64 (2.0.0-5) ...\n",
            "Selecting previously unselected package libglew-dev:amd64.\n",
            "Preparing to unpack .../libglew-dev_2.0.0-5_amd64.deb ...\n",
            "Unpacking libglew-dev:amd64 (2.0.0-5) ...\n",
            "Selecting previously unselected package libosmesa6:amd64.\n",
            "Preparing to unpack .../libosmesa6_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libosmesa6:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package libosmesa6-dev:amd64.\n",
            "Preparing to unpack .../libosmesa6-dev_20.0.8-0ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking libosmesa6-dev:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libosmesa6:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Setting up libglew2.0:amd64 (2.0.0-5) ...\n",
            "Setting up libglew-dev:amd64 (2.0.0-5) ...\n",
            "Setting up libosmesa6-dev:amd64 (20.0.8-0ubuntu1~18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  patchelf\n",
            "0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 46.5 kB of archives.\n",
            "After this operation, 130 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 patchelf amd64 0.9-1 [46.5 kB]\n",
            "Fetched 46.5 kB in 0s (136 kB/s)\n",
            "Selecting previously unselected package patchelf.\n",
            "(Reading database ... 155677 files and directories currently installed.)\n",
            "Preparing to unpack .../patchelf_0.9-1_amd64.deb ...\n",
            "Unpacking patchelf (0.9-1) ...\n",
            "Setting up patchelf (0.9-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting free-mujoco-py\n",
            "  Downloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 12.2 MB/s \n",
            "\u001b[?25hCollecting glfw<2.0.0,>=1.4.0\n",
            "  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n",
            "\u001b[K     |████████████████████████████████| 203 kB 61.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.15.0)\n",
            "Collecting fasteners==0.15\n",
            "  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (0.29.30)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.7/dist-packages (from free-mujoco-py) (1.21.6)\n",
            "Collecting imageio<3.0.0,>=2.9.0\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 50.1 MB/s \n",
            "\u001b[?25hCollecting monotonic>=0.1\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fasteners==0.15->free-mujoco-py) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.21)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 58.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow, monotonic, imageio, glfw, fasteners, free-mujoco-py\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 imageio-2.19.3 monotonic-1.6 pillow-9.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!apt-get install -y \\\n",
        "    libgl1-mesa-dev \\\n",
        "    libgl1-mesa-glx \\\n",
        "    libglew-dev \\\n",
        "    libosmesa6-dev \\\n",
        "    software-properties-common\n",
        "\n",
        "!apt-get install -y patchelf\n",
        "!pip install free-mujoco-py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvBkQ0-2TIGI"
      },
      "source": [
        "## Cherry TRPO MAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZleUELMTDCf"
      },
      "outputs": [],
      "source": [
        "!pip install cherry-rl learn2learn &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1cjFZVuS3U2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "import cherry as ch\n",
        "import gym\n",
        "import numpy as np\n",
        "import torch\n",
        "from cherry.algorithms import a2c, trpo, ppo\n",
        "from cherry.models.robotics import LinearValue\n",
        "from tqdm import tqdm\n",
        "\n",
        "import learn2learn as l2l\n",
        "\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from torch import autograd\n",
        "from torch.distributions.kl import kl_divergence\n",
        "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
        "from torch.distributions import Normal, Categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x6TJOktOIcF"
      },
      "outputs": [],
      "source": [
        "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
        "    torch.nn.init.orthogonal_(layer.weight, std)\n",
        "    torch.nn.init.constant_(layer.bias, bias_const)\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDEKGt5KONHM"
      },
      "outputs": [],
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, env, lr, hidden_size=100):\n",
        "        super().__init__()\n",
        "        self.input_size = env.observation_space.shape[0]\n",
        "        self.actor_output_size = env.action_space.shape[0]\n",
        "\n",
        "        self.l1 = layer_init(nn.Linear(self.input_size, hidden_size))\n",
        "        self.l2 = layer_init(nn.Linear(hidden_size, hidden_size))\n",
        "        self.output = layer_init(nn.Linear(hidden_size, self.actor_output_size), std=0.01)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.distribution = ch.distributions.ActionDistribution(env)\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr, eps=1e-5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.l1(x))\n",
        "        x = self.activation(self.l2(x))\n",
        "        x = self.output(x)\n",
        "        mass = self.distribution(x)\n",
        "\n",
        "        return mass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dbv0dy_WOOf9"
      },
      "outputs": [],
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, env, lr=0.01, hidden_size=32):\n",
        "        super().__init__()\n",
        "        self.input_size = env.observation_space.shape[0]\n",
        "        self.critic_output_size = 1\n",
        "\n",
        "        self.l1 = layer_init(nn.Linear(self.input_size, hidden_size))\n",
        "        self.l2 = layer_init(nn.Linear(hidden_size, hidden_size))\n",
        "        self.critic_head = layer_init(nn.Linear(hidden_size, self.critic_output_size), std=1.)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr, eps=1e-5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.l1(x))\n",
        "        x = self.activation(self.l2(x))\n",
        "        value = self.critic_head(x)\n",
        "\n",
        "        return value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo-Wb3A6YQPw"
      },
      "source": [
        "```\n",
        "for _ in trainer.step_epochs():\n",
        "\n",
        "    tasks = self._task_sampler.sample(self._meta_batch_size)\n",
        "    theta = dict(self._policy.named_parameters())\n",
        "    for i, env_up in enumerate(tasks):\n",
        "        clone = self.policy.clone()\n",
        "        for j in range(self._num_grad_updates + 1):\n",
        "            episodes = trainer.obtain_episodes(trainer.step_itr,\n",
        "                                                env_update=env_up)\n",
        "            batch_samples = self._process_samples(episodes)\n",
        "            all_samples[i].append(batch_samples)\n",
        "\n",
        "            # The last iteration does only sampling but no adapting\n",
        "            if j < self._num_grad_updates:\n",
        "                # A grad need to be kept for the next grad update\n",
        "                # Except for the last grad update\n",
        "                require_grad = j < self._num_grad_updates - 1\n",
        "\n",
        "                self._adapt(batch_samples, set_grad=require_grad)\n",
        "                #################################################\n",
        "                loss = self._inner_algo._compute_loss(*batch_samples[1:])\n",
        "                self._inner_optimizer.set_grads_none()\n",
        "                loss.backward(create_graph=set_grad)\n",
        "                self._inner_optimizer.step()\n",
        "\n",
        "        all_params.append(dict(self._policy.named_parameters()))\n",
        "        # Restore to pre-updated policy\n",
        "        update_module_params(self._policy, theta)\n",
        "\n",
        "\n",
        "    meta_objective = self._compute_meta_loss(all_samples, all_params)\n",
        "    ##########\n",
        "    theta = dict(self._policy.named_parameters())\n",
        "    old_theta = dict(self._old_policy.named_parameters())\n",
        "\n",
        "    losses = []\n",
        "    for task_samples, task_params in zip(all_samples, all_params):\n",
        "        for i in range(self._num_grad_updates):\n",
        "            require_grad = i < self._num_grad_updates - 1 or set_grad\n",
        "            self._adapt(task_samples[i], set_grad=require_grad)\n",
        "\n",
        "        update_module_params(self._old_policy, task_params)\n",
        "        with torch.set_grad_enabled(set_grad):\n",
        "            # pylint: disable=protected-access\n",
        "            last_update = task_samples[-1]\n",
        "            loss = self._inner_algo._compute_loss(*last_update[1:])\n",
        "        losses.append(loss)\n",
        "\n",
        "        update_module_params(self._policy, theta)\n",
        "        update_module_params(self._old_policy, old_theta)\n",
        "\n",
        "    return torch.stack(losses).mean()\n",
        "\n",
        "    zero_optim_grads(self._meta_optimizer)\n",
        "    meta_objective.backward()\n",
        "    self._meta_optimize(all_samples, all_params)\n",
        "\n",
        "    trainer.step_itr += 1\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIPEWKrndmIl"
      },
      "outputs": [],
      "source": [
        "class MAMLPPO():\n",
        "    def __init__(self, env,\n",
        "                 actor_class=Actor, critic_class=Critic, \n",
        "                 actor_args=dict(), critic_args=dict(),\n",
        "                 adapt_lr=1e-2, meta_lr=1e-2, \n",
        "                 adapt_steps=1, ppo_steps=5,\n",
        "                 adapt_batch_size=20, meta_batch_size=20,\n",
        "                 gamma=0.99, tau=1.0,\n",
        "                 policy_clip=0.2, value_clip=None,\n",
        "                 seed=42,\n",
        "                 device='cpu', name=\"MAML-PPO\", tensorboard_log=None):\n",
        "        \n",
        "        self.device = torch.device(device)\n",
        "        # random.seed(seed)\n",
        "        # np.random.seed(seed)\n",
        "        # torch.manual_seed(seed)\n",
        "        # if device == 'cuda':\n",
        "        #     torch.cuda.manual_seed(seed)\n",
        "\n",
        "        env = ch.envs.ActionSpaceScaler(env)\n",
        "        # env.seed(seed)\n",
        "        env.set_task(env.sample_tasks(1)[0])\n",
        "        self.env = ch.envs.Torch(env)\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.adapt_lr = adapt_lr\n",
        "        self.meta_lr = meta_lr\n",
        "        self.adapt_steps = adapt_steps\n",
        "        self.adapt_batch_size = adapt_batch_size\n",
        "        self.meta_batch_size = meta_batch_size\n",
        "        self.policy_clip = policy_clip\n",
        "        self.value_clip = value_clip\n",
        "        self.ppo_steps = ppo_steps\n",
        "\n",
        "        # self.backtrack_factor = backtrack_factor\n",
        "        # self.ls_max_steps = ls_max_steps\n",
        "        # self.max_kl = max_kl\n",
        "\n",
        "        policy = Actor(env, lr=meta_lr, **actor_args).to(device)\n",
        "        self.policy = l2l.algorithms.MAML(policy, lr=adapt_lr)\n",
        "        self.meta_optimizer = torch.optim.Adam(self.policy.parameters(), lr=meta_lr)\n",
        "        # self.baseline = Critic(env, lr=meta_lr, **critic_args).to(device)\n",
        "        self.baseline = Critic(env, **critic_args).to(device)\n",
        "        # self.baseline = LinearValue(env.state_size, env.action_size)\n",
        "\n",
        "\n",
        "    def collect_steps(self, policy, n_episodes):\n",
        "        replay = ch.ExperienceReplay(device=self.device)\n",
        "        for i in range(n_episodes):\n",
        "            state = self.env.reset()\n",
        "\n",
        "            while True:\n",
        "                with torch.no_grad():\n",
        "                    mass = policy(state)\n",
        "                action = mass.sample()\n",
        "                log_prob = mass.log_prob(action).mean(dim=1, keepdim=True)\n",
        "                next_state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "                replay.append(state,\n",
        "                            action,\n",
        "                            reward,\n",
        "                            next_state,\n",
        "                            done,\n",
        "                            log_prob=log_prob)\n",
        "                \n",
        "                if done:\n",
        "                    break\n",
        "\n",
        "                state = next_state\n",
        "\n",
        "        with torch.no_grad():\n",
        "            next_state_value = self.baseline(replay[-1].next_state)\n",
        "        values = self.baseline(replay.state())\n",
        "\n",
        "        advantages = ch.generalized_advantage(self.gamma,\n",
        "                                                self.tau,\n",
        "                                                replay.reward(),\n",
        "                                                replay.done(),\n",
        "                                                values.detach(),\n",
        "                                                next_state_value)\n",
        "        returns = advantages + values.detach()\n",
        "        advantages = ch.normalize(advantages, epsilon=1e-8)\n",
        "\n",
        "        for i, sars in enumerate(replay):\n",
        "            sars.returns = returns[i]\n",
        "            sars.advantage = advantages[i]\n",
        "\n",
        "        # values_pred = self.baseline(replay.state())\n",
        "        if self.value_clip:\n",
        "            value_loss = ppo.state_value_loss(values,\n",
        "                                            replay.value(),\n",
        "                                            returns,\n",
        "                                            clip=self.value_clip)\n",
        "        else:\n",
        "            value_loss = a2c.state_value_loss(values, returns)\n",
        "\n",
        "        self.baseline.optimizer.zero_grad()\n",
        "        value_loss.backward()\n",
        "        self.baseline.optimizer.step()\n",
        "\n",
        "        # self.baseline.fit(replay.state(), returns)\n",
        "        return replay\n",
        "\n",
        "\n",
        "    def fast_adapt(self, clone, train_episodes):\n",
        "        for ppo_epoch in range(self.ppo_steps):\n",
        "            new_density = clone(train_episodes.state())\n",
        "            new_log_probs = new_density.log_prob(train_episodes.action()).mean(dim=1, keepdim=True)\n",
        "\n",
        "            # Compute the policy loss\n",
        "            loss = ppo.policy_loss(new_log_probs, \n",
        "                                   train_episodes.log_prob(), \n",
        "                                   train_episodes.advantage(), \n",
        "                                   clip=self.policy_clip)\n",
        "            clone.adapt(loss)\n",
        "\n",
        "\n",
        "    def train(self, num_iterations=100):\n",
        "        for iteration in range(num_iterations):\n",
        "            iteration_reward = 0.0\n",
        "            iteration_replays = []\n",
        "            iteration_policies = []\n",
        "            iter_loss = 0.0\n",
        "\n",
        "            for task_config in tqdm(self.env.sample_tasks(self.meta_batch_size), leave=False, desc='Data'):\n",
        "                clone = self.policy.clone()\n",
        "                self.env.set_task(task_config)\n",
        "                task_replay = []\n",
        "\n",
        "                # Fast Adapt\n",
        "                for step in range(self.adapt_steps):\n",
        "                    train_episodes = self.collect_steps(clone, n_episodes=self.adapt_batch_size)\n",
        "                    self.fast_adapt(clone, train_episodes)\n",
        "\n",
        "                # Compute Validation Loss\n",
        "                valid_episodes = self.collect_steps(clone, n_episodes=self.adapt_batch_size)\n",
        "                iteration_reward += valid_episodes.reward().sum().item() / self.adapt_batch_size\n",
        "\n",
        "                new_density = clone(valid_episodes.state())\n",
        "                new_log_probs = new_density.log_prob(valid_episodes.action()).mean(dim=1, keepdim=True)\n",
        "                # Compute the policy loss\n",
        "                valid_loss = ppo.policy_loss(new_log_probs,\n",
        "                                             valid_episodes.log_prob(), \n",
        "                                             valid_episodes.advantage(),\n",
        "                                             clip=self.policy_clip)\n",
        "                iter_loss += valid_loss\n",
        "\n",
        "            # Print statistics\n",
        "            print('\\nIteration', iteration)\n",
        "            adaptation_reward = iteration_reward / self.meta_batch_size\n",
        "            print('adaptation_reward', adaptation_reward)\n",
        "\n",
        "            av_loss = iter_loss / self.meta_batch_size\n",
        "\n",
        "            av_loss.backward()\n",
        "            self.meta_optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vspfc_97Pb0O"
      },
      "outputs": [],
      "source": [
        "env = gym.make('Particles2D-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhHiZBGTPkJZ",
        "outputId": "9141c6d1-dadc-4258-ad4d-d9e7f455d2e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        }
      ],
      "source": [
        "aa = MAMLPPO(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UAU7YG-Pn34",
        "outputId": "4f9342df-457b-4e07-e01f-8baa6ee89a81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 0\n",
            "adaptation_reward -72.14244812011718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "adaptation_reward -64.69322326660156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 2\n",
            "adaptation_reward -60.82671463012696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 3\n",
            "adaptation_reward -51.2676643371582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 4\n",
            "adaptation_reward -46.76594894409181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 5\n",
            "adaptation_reward -44.23233413696289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 6\n",
            "adaptation_reward -43.03200332641602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 7\n",
            "adaptation_reward -46.263327941894524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 8\n",
            "adaptation_reward -42.709817886352546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 9\n",
            "adaptation_reward -38.209377212524416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 10\n",
            "adaptation_reward -34.073232421875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 11\n",
            "adaptation_reward -35.51377508163452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 12\n",
            "adaptation_reward -39.245884017944334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 13\n",
            "adaptation_reward -44.06808357238769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 14\n",
            "adaptation_reward -31.109482975006095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 15\n",
            "adaptation_reward -44.82811918258666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 16\n",
            "adaptation_reward -49.77313026428222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 17\n",
            "adaptation_reward -55.34247619628907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 18\n",
            "adaptation_reward -51.14251829147337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 19\n",
            "adaptation_reward -57.62670774459838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 20\n",
            "adaptation_reward -53.029380874633794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 21\n",
            "adaptation_reward -55.511291732788074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 22\n",
            "adaptation_reward -57.05236518859863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 23\n",
            "adaptation_reward -55.101924133300784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 24\n",
            "adaptation_reward -54.09776824951172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 25\n",
            "adaptation_reward -47.6008623123169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 26\n",
            "adaptation_reward -48.87730895996094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 27\n",
            "adaptation_reward -46.724959716796874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 28\n",
            "adaptation_reward -53.530391159057615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 29\n",
            "adaptation_reward -43.14779594421387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 30\n",
            "adaptation_reward -38.936241912841794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 31\n",
            "adaptation_reward -46.90168914794922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 32\n",
            "adaptation_reward -41.86559139251709\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 33\n",
            "adaptation_reward -44.11037166595459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 34\n",
            "adaptation_reward -37.805352020263676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 35\n",
            "adaptation_reward -36.87970939636231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 36\n",
            "adaptation_reward -44.461333007812506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 37\n",
            "adaptation_reward -38.69464485168457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 38\n",
            "adaptation_reward -48.24568592071533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 39\n",
            "adaptation_reward -54.646986465454106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 40\n",
            "adaptation_reward -58.7583726501465\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 41\n",
            "adaptation_reward -68.95524559020997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 42\n",
            "adaptation_reward -66.85666732788087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 43\n",
            "adaptation_reward -81.63729476928712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 44\n",
            "adaptation_reward -116.36980072021485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 45\n",
            "adaptation_reward -148.4190576171875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 46\n",
            "adaptation_reward -529.273818359375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 47\n",
            "adaptation_reward -545.0820068359374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 48\n",
            "adaptation_reward -521.9780322265626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 49\n",
            "adaptation_reward -534.7763208007813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 50\n",
            "adaptation_reward -534.2482788085938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 51\n",
            "adaptation_reward -548.0662548828125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 52\n",
            "adaptation_reward -436.07673583984376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 53\n",
            "adaptation_reward -311.8321166992188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 54\n",
            "adaptation_reward -357.8904663085938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 55\n",
            "adaptation_reward -485.66236083984387\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 56\n",
            "adaptation_reward -627.297911376953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 57\n",
            "adaptation_reward -660.2115942382814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 58\n",
            "adaptation_reward -668.045947265625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 59\n",
            "adaptation_reward -670.2789208984377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 60\n",
            "adaptation_reward -671.3915136718749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 61\n",
            "adaptation_reward -666.0001757812499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 62\n",
            "adaptation_reward -675.0311645507815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 63\n",
            "adaptation_reward -667.0026855468749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 64\n",
            "adaptation_reward -634.3038525390625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 65\n",
            "adaptation_reward -618.6332006835938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 66\n",
            "adaptation_reward -599.4000756835937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 67\n",
            "adaptation_reward -583.4839428710937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 68\n",
            "adaptation_reward -560.2422021484374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 69\n",
            "adaptation_reward -543.1413183593748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 70\n",
            "adaptation_reward -536.8820166015624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 71\n",
            "adaptation_reward -535.0161376953126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 72\n",
            "adaptation_reward -519.8163281249999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 73\n",
            "adaptation_reward -523.6207202148438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 74\n",
            "adaptation_reward -525.7329833984375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 75\n",
            "adaptation_reward -522.8726367187501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 76\n",
            "adaptation_reward -519.711171875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 77\n",
            "adaptation_reward -525.5798388671875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 78\n",
            "adaptation_reward -531.2727221679687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 79\n",
            "adaptation_reward -521.0558715820313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 80\n",
            "adaptation_reward -509.23310791015626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 81\n",
            "adaptation_reward -508.65889160156246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 82\n",
            "adaptation_reward -520.7678686523439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 83\n",
            "adaptation_reward -509.2552709960938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 84\n",
            "adaptation_reward -500.5760253906251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 85\n",
            "adaptation_reward -516.3190454101561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 86\n",
            "adaptation_reward -507.88580078125017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 87\n",
            "adaptation_reward -513.3900317382812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 88\n",
            "adaptation_reward -495.6379013293981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 89\n",
            "adaptation_reward -521.7659228515626\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 90\n",
            "adaptation_reward -526.4571997070312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 91\n",
            "adaptation_reward -517.4612158203125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 92\n",
            "adaptation_reward -514.4419921875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 93\n",
            "adaptation_reward -512.3902294921875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 94\n",
            "adaptation_reward -503.57342041015636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 95\n",
            "adaptation_reward -514.4265747070312\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 96\n",
            "adaptation_reward -501.15360351562504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 97\n",
            "adaptation_reward -506.7809838867187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 98\n",
            "adaptation_reward -510.89814453125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 99\n",
            "adaptation_reward -515.21685546875\n"
          ]
        }
      ],
      "source": [
        "aa.train(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYFpGEDjPwXy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MAML PPO.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}